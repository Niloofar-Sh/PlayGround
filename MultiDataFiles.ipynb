{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_nonNumeric_col(df):\n",
    "    '''\n",
    "    seperates the numeric and non-numeric columns.\n",
    "    '''\n",
    "    return [col for col in df.columns if isinstance(col, int)], [col for col in df.columns if isinstance(col, str)]\n",
    "def interpolate_full_range(df):\n",
    "    # Extract numeric column names\n",
    "    numeric_cols, nonNumeric_cols = numeric_nonNumeric_col(df)\n",
    "\n",
    "    # Function to fill the row with the first valid value\n",
    "    def fill_initial_nans(series):\n",
    "        first_valid_idx = series.first_valid_index()\n",
    "        last_valid_idx = series.last_valid_index()\n",
    "        if first_valid_idx is not None:  # Ensure there's a valid index\n",
    "            series.loc[:first_valid_idx] = series[first_valid_idx]   # Fill initial NaNs\n",
    "        if last_valid_idx is not None:\n",
    "            series.loc[last_valid_idx:] = series[last_valid_idx]\n",
    "        return series\n",
    "\n",
    "    # Apply the function row-wise\n",
    "    df[numeric_cols] = df[numeric_cols].apply(fill_initial_nans, axis=1)\n",
    "\n",
    "    # Create full range of numeric columns from min to max\n",
    "    full_range = np.arange(min(numeric_cols), max(numeric_cols) + 1)\n",
    "\n",
    "    # Reindex DataFrame to include all missing columns\n",
    "    df_numeric = df[numeric_cols].reindex(columns=full_range)\n",
    "\n",
    "    # Interpolate missing values row-wise\n",
    "    df_interpolated = df_numeric.interpolate(method='linear', axis=1)\n",
    "\n",
    "    # Combine back with categorical columns\n",
    "    return pd.concat([df_interpolated, df[nonNumeric_cols]], axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "class InteractivePlotGen:\n",
    "    def __init__(self, cumulative, new, treatments_to_merge=False):\n",
    "        self.cumulative = cumulative\n",
    "        self.new = new\n",
    "        self.treatments_to_merge = treatments_to_merge\n",
    "    def _BB_treatment_plot(self):\n",
    "        treatments = list(self.cumulative.keys())\n",
    "        full_doy_range = self.cumulative[treatments[0]]['all_loc'].index\n",
    "        # Create 2 subplots for cumulative and new buds over time\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=[f\"Cumulative Buds\", f\"Daily New Buds\"])\n",
    "\n",
    "        # Add first subplot (Cumulative Sum)\n",
    "        [fig.add_trace(\n",
    "            go.Scatter(x=full_doy_range, y=self.cumulative[treatment]['all_loc']['mean'], mode='lines+markers', name=treatment), row=1, col=1) for treatment in treatments]\n",
    "        # if treatments_to_merge is a list with length > 1, means at least two treatments are given to be merged, else it won't plot merged\n",
    "        if isinstance(self.treatments_to_merge,list) and len(self.treatments_to_merge)>1:\n",
    "            merged_treatments = pd.concat([self.cumulative[treatment]['all_loc']['mean'] for treatment in self.treatments_to_merge], axis=1).mean(axis=1)\n",
    "            std_concatenated = pd.concat([self.cumulative[treatment]['all_loc']['std'] for treatment in self.treatments_to_merge], axis=1)\n",
    "            pooled_std = np.sqrt((std_concatenated**2).mean(axis=1)) # RMS method\n",
    "            fig.add_trace(go.Scatter(x=full_doy_range, y=merged_treatments, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True),name=f\"{self.treatments_to_merge}\"), row=1, col=1)\n",
    "\n",
    "        # Fit polynomial over all treatments\n",
    "        # fig.add_trace(\n",
    "        #     go.Scatter(x=full_doy_range, y=self.fitted_poly['cumulative'], mode='lines', line=dict(color=\"black\", dash=\"dash\") , name='All Trtmnts (Cumulative)--fitted'),\n",
    "        #     row=1, col=1)\n",
    "\n",
    "        # Add second subplot (Daily New Buds)\n",
    "        [fig.add_trace(\n",
    "            go.Scatter(x=full_doy_range, y=self.new[treatment]['all_loc']['mean'], mode='lines+markers', name=treatment), row=2, col=1) for treatment in treatments]\n",
    "        # if treatments_to_merge is a list with length > 1, means at least two treatments are given to be merged, else it won't plot merged\n",
    "        if isinstance(self.treatments_to_merge,list) and len(self.treatments_to_merge)>1:\n",
    "            merged_treatments = pd.concat([self.new[treatment]['all_loc']['mean'] for treatment in self.treatments_to_merge], axis=1).mean(axis=1)\n",
    "            std_concatenated = pd.concat([self.new[treatment]['all_loc']['std'] for treatment in self.treatments_to_merge], axis=1)\n",
    "            pooled_std = np.sqrt((std_concatenated**2).mean(axis=1)) # RMS method\n",
    "            fig.add_trace(go.Scatter(x=full_doy_range, y=merged_treatments, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True),name=f\"{self.treatments_to_merge}\"), row=2, col=1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # # Fit polynomial over all treatments\n",
    "        # fig.add_trace(\n",
    "        #     go.Scatter(x=full_doy_range, y=self.fitted_poly['new'], mode='lines', line=dict(color=\"black\", dash=\"dash\") , name='All Trtmnts (New)--fitted'),\n",
    "        #     row=2, col=1)\n",
    "\n",
    "        # Set y-axis labels for each subplot\n",
    "        [fig.update_yaxes(title_text=\"Mean bud number\", row=row_num, col=1) for row_num in [1,2]]\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=\"Cumulative & Daily New Buds Over Time\",\n",
    "            showlegend=True,\n",
    "            height=700, width=1200)\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            tickmode=\"array\", \n",
    "            tickvals=full_doy_range,  # Use all available dates as ticks\n",
    "            tickangle=45)  # Rotate for better visibility\n",
    "\n",
    "        # Save as interactive HTML\n",
    "        fig.write_html(\"bud_num_interactive_plot.html\")\n",
    "    # def _origin_predict_plot(self):\n",
    "    #     # Create 2 subplots for cumulative and new buds (original vs predicted)\n",
    "    #     fig = make_subplots(rows=2, cols=1, subplot_titles=[\"Cumulative Buds\", \"Daily New Buds\"])\n",
    "\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.fitted_poly['cumulative'], y=self.all_trtmnts['cumulative'].values, mode='markers',\n",
    "    #         name='Original vs Fitted', marker=dict(color='blue')), row=1, col=1)\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.all_trtmnts['cumulative'].values, y=self.all_trtmnts['cumulative'].values, mode='lines',\n",
    "    #         name='Cumulative 1:1', marker=dict(color='red')), row=1, col=1)\n",
    "        \n",
    "    #     # Second subplot\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.fitted_poly['new'], y=self.all_trtmnts['new'].values, mode='markers',\n",
    "    #         name='Original vs Fitted', marker=dict(color='blue')), row=2, col=1)\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.all_trtmnts['new'].values, y=self.all_trtmnts['new'].values, mode='lines',\n",
    "    #         name='New 1:1', marker=dict(color='red')), row=2, col=1)\n",
    "        \n",
    "    #     # Add stats as an annotation\n",
    "    #     fig.add_annotation(\n",
    "    #         text=f\"R2 = {self.stats_cumulative['R2']:.2f}<br>NRMSE = {self.stats_cumulative['NRMSE']:.2f}\",\n",
    "    #         x=self.fitted_poly['cumulative'][int(len(self.fitted_poly['cumulative'])/3)],  # Position at 1/3 of x-axis\n",
    "    #         y=max(self.all_trtmnts['cumulative'].values),      # Position near the top of y-axis\n",
    "    #         showarrow=False,\n",
    "    #         xref=\"x1\",  # Referencing x-axis for subplot 1\n",
    "    #         yref=\"y1\",  # Referencing y-axis for subplot 1\n",
    "    #         font=dict(size=10, color=\"black\"),\n",
    "    #         align=\"left\",\n",
    "    #         bordercolor=\"black\",\n",
    "    #         borderwidth=1,\n",
    "    #         bgcolor=\"white\")\n",
    "        \n",
    "    #     fig.add_annotation(\n",
    "    #         text=f\"R2 = {self.stats_new['R2']:.2f}<br>NRMSE = {self.stats_new['NRMSE']:.2f}\",\n",
    "    #         x=self.fitted_poly['new'][int(len(self.fitted_poly['new'])/3)],  # Position at 1/3 of x-axis\n",
    "    #         y=max(self.all_trtmnts['new'].values),      # Position near the top of y-axis\n",
    "    #         showarrow=False,\n",
    "    #         xref=\"x2\",  # Referencing x-axis for subplot 2\n",
    "    #         yref=\"y2\",  # Referencing y-axis for subplot 2\n",
    "    #         font=dict(size=10, color=\"black\"),\n",
    "    #         align=\"left\",\n",
    "    #         bordercolor=\"black\",\n",
    "    #         borderwidth=1,\n",
    "    #         bgcolor=\"white\")\n",
    "        \n",
    "    #     # Set x-axis & y-axis labels for each subplot\n",
    "    #     [fig.update_yaxes(title_text=\"Original\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "    #     [fig.update_xaxes(title_text=\"Predicted\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "    #     # Customize layout\n",
    "    #     fig.update_layout(title=\"Original vs. Fitted Data\", template=\"plotly_white\")\n",
    "\n",
    "    #     # Save as interactive HTML file\n",
    "    #     fig.write_html(\"original vs predicted.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')\n",
    "# Define the expected column names for the final concatenated DataFrame\n",
    "CULTIVAR = \"Cultivar\" \n",
    "TREATMENT = \"Treatment\"\n",
    "LOCATION = \"Location\"\n",
    "\n",
    "# Select the interpolation method\n",
    "interpolation_method = 'linear'#, 'akima', 'pchip', 'quadratic'\n",
    "\n",
    "def is_date_column(col):\n",
    "    # Function to check if column names are dates\n",
    "    try:\n",
    "        pd.to_datetime(col)  # Try converting the column name to a date\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "with open(\"config_MultiDataFiles.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Load the Excel file\n",
    "\n",
    "# Initialize an empty list to store filtered DataFrames\n",
    "filtered_dfs = []\n",
    "\n",
    "# Process each file mentioned in the config\n",
    "for file_name, file_info in config.items():\n",
    "    file_path = os.path.join(FOLDER_PATH, file_name)\n",
    "    # if not file_path.exists():\n",
    "    #     print(f\"Warning: {file_name} not found in {FOLDER_PATH}\")\n",
    "    #     continue\n",
    "\n",
    "    # Process each sheet\n",
    "    for sheet_info in file_info['sheets']:\n",
    "        # Extract sheet names, cultivars, and treatments\n",
    "        sheet_name = sheet_info['sheet_name']\n",
    "        location = sheet_info['location']\n",
    "        cultivar_col, cultivar_name = list(sheet_info['cultivar'].items())[0]\n",
    "        treatment_col, treatment_name = list(sheet_info['treatments'].items())[0]\n",
    "\n",
    "        xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "        df = pd.read_excel(xls, sheet_name = sheet_name)\n",
    "\n",
    "        # Ensure columns exist before filtering\n",
    "        if cultivar_col not in df.columns or treatment_col not in df.columns:\n",
    "            print(f\"Warning: Missing required column(s) in {file_name} - sheet: {sheet_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Rename the Dates to Days of Year (DOY)\n",
    "        doy_column = [pd.to_datetime(col).dayofyear for col in df.columns if is_date_column(col)]\n",
    "        df.rename(columns={col:pd.to_datetime(col).dayofyear for col in df.columns if is_date_column(col)}, inplace=True)\n",
    "\n",
    "        # Apply filtering for the given cultivar & treatments\n",
    "        filtered_df = df[df[cultivar_col].isin([cultivar_name]) & df[treatment_col].isin([treatment_name])]\n",
    "\n",
    "        # Rename columns\n",
    "        columns_to_select = [cultivar_col] + [treatment_col] + doy_column  # Ensure it's a flat list\n",
    "        filtered_df = filtered_df[columns_to_select]\n",
    "        filtered_df.rename(columns={cultivar_col: CULTIVAR, treatment_col: TREATMENT}, inplace=True)\n",
    "        # Add the LOCATION column to the DataFrame\n",
    "        filtered_df[LOCATION] = location\n",
    "\n",
    "        # Remove rows with any NaN values\n",
    "        filtered_df = filtered_df.dropna()\n",
    "\n",
    "        # Reset index \n",
    "        filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "        # Store the filtered DataFrame\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "final_df = pd.concat(filtered_dfs, ignore_index=True, sort=True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate cumulative/new daily buds {DayOfYear: [mean , std]} for all treatments & all locations\n",
    "cumulative_daily = defaultdict(lambda: dict())\n",
    "new_daily = defaultdict(lambda: dict())\n",
    "final_df_treatment_loc_specific = defaultdict(lambda: dict())\n",
    "\n",
    "all_treatments = final_df[TREATMENT].unique()\n",
    "all_locations = final_df[LOCATION].unique()\n",
    "\n",
    "for trtmnt in all_treatments:\n",
    "    final_df_treatment_loc_specific[trtmnt]['all_loc'] = interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "    # Calculate mean & std for the number of buds per day\n",
    "    numeric_columns, nonNumeric_cols = numeric_nonNumeric_col(final_df_treatment_loc_specific[trtmnt]['all_loc'])\n",
    "\n",
    "    # For cumulative bud num (mean & std), for all locations\n",
    "    cumulative_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(final_df_treatment_loc_specific[trtmnt]['all_loc'][day].mean(),2) for day in numeric_columns], [round(final_df_treatment_loc_specific[trtmnt]['all_loc'][day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "    \n",
    "    # Taking the daily differences between the interpolated days\n",
    "    diff_daily = final_df_treatment_loc_specific[trtmnt]['all_loc'][numeric_columns].copy()\n",
    "    diff_daily.iloc[:, 1:] = diff_daily.iloc[:, 1:].values - diff_daily.iloc[:, :-1].values\n",
    "    daily_diff = pd.concat([diff_daily,final_df_treatment_loc_specific[trtmnt]['all_loc'][nonNumeric_cols]], axis=1)\n",
    "\n",
    "    # For new daily bud num (mean & std), for all locations \n",
    "    new_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff[day].mean(),2) for day in numeric_columns], [round(daily_diff[day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "\n",
    "    \n",
    "    for loc in all_locations:\n",
    "        if final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])].empty: # continue if for a given treatment the current location doesn't exist\n",
    "            continue\n",
    "        final_df_treatment_loc_specific[trtmnt][loc] = interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])])\n",
    "\n",
    "        # For cumulative bud num (mean & std), per location\n",
    "        cumulative_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(final_df_treatment_loc_specific[trtmnt][loc][day].mean(),2) for day in numeric_columns], [round(final_df_treatment_loc_specific[trtmnt][loc][day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "        \n",
    "        # Taking the daily differences between the interpolated days\n",
    "        diff_daily = final_df_treatment_loc_specific[trtmnt][loc][numeric_columns].copy()\n",
    "        diff_daily.iloc[:, 1:] = diff_daily.iloc[:, 1:].values - diff_daily.iloc[:, :-1].values\n",
    "        daily_diff = pd.concat([diff_daily,final_df_treatment_loc_specific[trtmnt][loc][nonNumeric_cols]], axis=1)\n",
    "        # For new daily bud num (mean & std), for all locations \n",
    "        new_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff[day].mean(),2) for day in numeric_columns], [round(daily_diff[day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = InteractivePlotGen(cumulative_daily, new_daily, ['Con1', 'Con2', 'Control', 'Control early', 'Control late'])\n",
    "plotter._BB_treatment_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
