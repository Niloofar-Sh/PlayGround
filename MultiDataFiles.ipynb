{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\hranfs\\\\Documents\\\\VS code\\\\PlayGround\\\\utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InteractivePlotGen:\n",
    "    def __init__(self, cumulative, new, merge_dict=False):\n",
    "        self.cumulative = cumulative\n",
    "        self.new = new\n",
    "        self.merge_dict = merge_dict\n",
    "        self.specifications = list(self.cumulative.keys()) # to get the index values\n",
    "\n",
    "    def _treatment_merge(self, df, merge_list):\n",
    "        merged_treatments = pd.concat([df[treatment]['median'] for treatment in merge_list], axis=1).median(axis=1)\n",
    "        std_concatenated = pd.concat([df[treatment]['std'] for treatment in merge_list], axis=1)\n",
    "        pooled_std = np.sqrt((std_concatenated**2).median(axis=1)) # RMS method\n",
    "        error_minus = np.minimum(pooled_std, merged_treatments)  # ensures y - error_minus >= 0\n",
    "        return merged_treatments, pooled_std, error_minus\n",
    "    \n",
    "    def _BB_treatment_plot(self, BB_threshold=False, Model_fitting=False):\n",
    "        full_doy_range = self.cumulative[self.specifications[0]].index\n",
    "        # Create 2 subplots for cumulative and new buds over time\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=[f\"Cumulative Buds\", f\"Daily New Buds\"])\n",
    "\n",
    "        # if the treatment_to_merge dict is not empty and is in the dict format start plotting the merged treatments\n",
    "        if isinstance(self.merge_dict,dict):\n",
    "            for merge_key, merge_list in self.merge_dict.items():\n",
    "                merged_treatments_cumulative, pooled_std, error_minus = self._treatment_merge(self.cumulative, merge_list)\n",
    "                fig.add_trace(go.Scatter(x=full_doy_range, y=merged_treatments_cumulative, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True, arrayminus=error_minus),name=f\"{merge_key}\"), row=1, col=1)\n",
    "\n",
    "                # Fit polynomial over all treatments\n",
    "                if Model_fitting==True:\n",
    "                    fitted_cumulative = utils.logistic_fit(np.arange(0,len(full_doy_range)), merged_treatments_cumulative)\n",
    "                    stats_cumulative = utils.calculate_fit_stats(merged_treatments_cumulative, fitted_cumulative)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=full_doy_range, y=fitted_cumulative, mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{merge_key}--fitted [R2 = {stats_cumulative['R2']:.2f}]'),\n",
    "                    row=1, col=1)\n",
    "\n",
    "                # Add an annotation at the BB crossing point\n",
    "                if BB_threshold is not False:\n",
    "                    BB = BB_threshold*np.max(merged_treatments_cumulative)\n",
    "                    idx = np.argmax(merged_treatments_cumulative >= BB) # Find the first index where y is greater than or equal to BB_threshold\n",
    "                    fig.add_annotation(\n",
    "                        x=list(full_doy_range)[idx],\n",
    "                        y=merged_treatments_cumulative.iloc[idx],\n",
    "                        text=f\"{list(full_doy_range)[idx]}\",\n",
    "                        showarrow=True,\n",
    "                        arrowhead=2)\n",
    "        # If there isn't a given dict foe merging, or the treatment is not supposed to be merged, plot each separately\n",
    "        for treatment in self.specifications:\n",
    "            if  isinstance(self.merge_dict,dict) == False or not any(treatment in values for values in self.merge_dict.values()):\n",
    "                # Add to the first subplot (Cumulative Sum)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=full_doy_range, y=self.cumulative[treatment]['median'], mode='lines+markers', error_y=dict(type='data', array=self.cumulative[treatment]['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.cumulative[treatment]['std'], self.cumulative[treatment]['median'])), name=treatment), row=1, col=1)\n",
    "\n",
    "\n",
    "        # if the treatment_to_merge dict is not empty and is in the dict format start plotting the merged treatments\n",
    "        if isinstance(self.merge_dict,dict):\n",
    "            for merge_key, merge_list in self.merge_dict.items():\n",
    "                merged_treatments_new, pooled_std, error_minus = self._treatment_merge(self.new, merge_list)\n",
    "                fig.add_trace(go.Scatter(x=full_doy_range, y=merged_treatments_new, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True, arrayminus=error_minus),name=f\"{merge_key}\"), row=2, col=1)\n",
    "\n",
    "                # Fit polynomial over all treatments\n",
    "                if Model_fitting==True:\n",
    "                    fitted_new = utils.gaussian_fit(np.arange(0,len(full_doy_range)), merged_treatments_new)\n",
    "                    stats_new = utils.calculate_fit_stats(merged_treatments_new, fitted_new)\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(x=full_doy_range, y=fitted_new, mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{merge_key}--fitted [R2 = {stats_new['R2']:.2f}]'),\n",
    "                        row=2, col=1)\n",
    "\n",
    "        # If there isn't a given dict foe merging, or the treatment is not supposed to be merged, plot each separately\n",
    "        for treatment in self.specifications:\n",
    "            if isinstance(self.merge_dict,dict) == False or not any(treatment in values for values in self.merge_dict.values()):\n",
    "                # Add to the second subplot (Daily New Buds)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=full_doy_range, y=self.new[treatment]['median'], mode='lines+markers', error_y=dict(type='data', array=self.new[treatment]['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.new[treatment]['std'], self.new[treatment]['median'])), name=treatment), row=2, col=1)\n",
    "\n",
    "\n",
    "        # Set y-axis labels for each subplot\n",
    "        [fig.update_yaxes(title_text=\"median bud number\", row=row_num, col=1) for row_num in [1,2]]\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=\"Cumulative & Daily New Buds Over Time (All locations)\",\n",
    "            showlegend=True,\n",
    "            height=700, width=1200)\n",
    "\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            tickmode=\"array\", \n",
    "            tickvals=full_doy_range,  # Use all available dates as ticks\n",
    "            tickangle=45,\n",
    "            tickfont=dict(size=8))  # Rotate for better visibility\n",
    "        \n",
    "\n",
    "        # Save as interactive HTML\n",
    "        fig.write_html(\"treatment_specific_BB.html\")\n",
    "    \n",
    "    def _BB_location_plot(self, BB_threshold=False, Model_fitting=False):\n",
    "        first_loc_key = self.specifications[0]\n",
    "        first_trtmnt_key = list(self.cumulative[first_loc_key].keys())[0]\n",
    "        full_doy_range = self.cumulative[first_loc_key][first_trtmnt_key].index\n",
    "        # Create 2 subplots for cumulative and new buds over time\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=[f\"Cumulative Buds\", f\"Daily New Buds\"])\n",
    "        for loc in self.specifications:\n",
    "            # Add to the first subplot (Cumulative Sum)\n",
    "            [fig.add_trace(\n",
    "                go.Scatter(x=full_doy_range, y=self.cumulative[loc][treatment]['median'], mode='lines+markers', error_y=dict(type='data', array=self.cumulative[loc][treatment]['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.cumulative[loc][treatment]['std'], self.cumulative[loc][treatment]['median'])), name=f'{loc}: {treatment}'), row=1, col=1) for treatment in self.cumulative[loc].keys()]\n",
    "                \n",
    "            # Fit polynomial over all treatments\n",
    "            if Model_fitting is True:\n",
    "                fitted_cumulative = {treatment: utils.logistic_fit(np.arange(0,len(full_doy_range)), self.cumulative[loc][treatment]['median']) for treatment in self.cumulative[loc].keys()}\n",
    "                stats_cumulative = {treatment: utils.calculate_fit_stats(self.cumulative[loc][treatment]['median'], fitted_cumulative[treatment]) for treatment in self.cumulative[loc].keys()}\n",
    "                [fig.add_trace(\n",
    "                    go.Scatter(x=full_doy_range, y=fitted_cumulative[treatment], mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{treatment}--fitted [R2 = {stats_cumulative[treatment]['R2']:.2f}]'),\n",
    "                row=1, col=1)  for treatment in self.cumulative[loc].keys()]\n",
    "\n",
    "            # Add an annotation at the BB crossing point\n",
    "            if BB_threshold is not False:\n",
    "                for treatment in self.cumulative[loc].keys():\n",
    "                    BB = BB_threshold*np.max(self.cumulative[loc][treatment]['median'])\n",
    "                    idx = np.argmax(self.cumulative[loc][treatment]['median'] >= BB) # Find the first index where y is greater than or equal to 0.1*BB\n",
    "                    fig.add_annotation(\n",
    "                        x=list(full_doy_range)[idx],\n",
    "                        y=self.cumulative[loc][treatment]['median'].iloc[idx],\n",
    "                        text=f\"{list(full_doy_range)[idx]}\",\n",
    "                        showarrow=True,\n",
    "                        arrowhead=2)\n",
    "                    \n",
    "        for loc in self.specifications:\n",
    "            # Add to the second subplot (New buds)\n",
    "            [fig.add_trace(\n",
    "                go.Scatter(x=full_doy_range, y=self.new[loc][treatment]['median'], mode='lines+markers', error_y=dict(type='data', array=self.new[loc][treatment]['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.new[loc][treatment]['std'], self.new[loc][treatment]['median'])), name=f'{loc}: {treatment}'), row=2, col=1) for treatment in self.new[loc].keys()]\n",
    "                \n",
    "            # Fit polynomial over all treatments\n",
    "            if Model_fitting is True:\n",
    "                fitted_new = {treatment: utils.logistic_fit(np.arange(0,len(full_doy_range)), self.new[loc][treatment]['median']) for treatment in self.new[loc].keys()}\n",
    "                stats_new = {treatment: utils.calculate_fit_stats(self.new[loc][treatment]['median'], fitted_new[treatment]) for treatment in self.new[loc].keys()}\n",
    "                [fig.add_trace(\n",
    "                    go.Scatter(x=full_doy_range, y=fitted_new[treatment], mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{treatment}--fitted [R2 = {stats_new[treatment]['R2']:.2f}]'),\n",
    "                row=2, col=1)  for treatment in self.new[loc].keys()]\n",
    "\n",
    "        # Set y-axis labels for each subplot\n",
    "        [fig.update_yaxes(title_text=\"median bud number\", row=row_num, col=1) for row_num in [1,2]]\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=\"Cumulative & Daily New Buds Over Time\",\n",
    "            showlegend=True,\n",
    "            height=700, width=1200)\n",
    "\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            tickmode=\"array\", \n",
    "            tickvals=full_doy_range,  # Use all available dates as ticks\n",
    "            tickangle=45,\n",
    "            tickfont=dict(size=8))  # Rotate for better visibility\n",
    "\n",
    "        \n",
    "        # Save as interactive HTML\n",
    "        fig.write_html(\"location_specific_BB.html\")\n",
    "    \n",
    "    def _origin_predict_plot(self):\n",
    "        # Create 2 subplots for cumulative and new buds (original vs predicted)\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=[\"Cumulative Buds\", \"Daily New Buds\"])\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.fitted_poly['cumulative'], y=self.all_trtmnts['cumulative'].values, mode='markers',\n",
    "            name='Original vs Fitted', marker=dict(color='blue')), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.all_trtmnts['cumulative'].values, y=self.all_trtmnts['cumulative'].values, mode='lines',\n",
    "            name='Cumulative 1:1', marker=dict(color='red')), row=1, col=1)\n",
    "        \n",
    "        # Second subplot\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.fitted_poly['new'], y=self.all_trtmnts['new'].values, mode='markers',\n",
    "            name='Original vs Fitted', marker=dict(color='blue')), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=self.all_trtmnts['new'].values, y=self.all_trtmnts['new'].values, mode='lines',\n",
    "            name='New 1:1', marker=dict(color='red')), row=2, col=1)\n",
    "        \n",
    "        # Add stats as an annotation\n",
    "        fig.add_annotation(\n",
    "            text=f\"R2 = {stats_cumulative['R2']:.2f}<br>NRMSE = {stats_cumulative['NRMSE']:.2f}\",\n",
    "            x=fitted_cumulative[int(len(fitted_cumulative)/3)],  # Position at 1/3 of x-axis\n",
    "            y=max(fitted_cumulative),      # Position near the top of y-axis\n",
    "            showarrow=False,\n",
    "            xref=\"x1\",  # Referencing x-axis for subplot 1\n",
    "            yref=\"y1\",  # Referencing y-axis for subplot 1\n",
    "            font=dict(size=10, color=\"black\"),\n",
    "            align=\"left\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            bgcolor=\"white\")\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            text=f\"R2 = {stats_new['R2']:.2f}<br>NRMSE = {stats_new['NRMSE']:.2f}\",\n",
    "            x=fitted_new[int(len(fitted_new)/3)],  # Position at 1/3 of x-axis\n",
    "            y=max(fitted_new),      # Position near the top of y-axis\n",
    "            showarrow=False,\n",
    "            xref=\"x2\",  # Referencing x-axis for subplot 2\n",
    "            yref=\"y2\",  # Referencing y-axis for subplot 2\n",
    "            font=dict(size=10, color=\"black\"),\n",
    "            align=\"left\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            bgcolor=\"white\")\n",
    "        \n",
    "        # Set x-axis & y-axis labels for each subplot\n",
    "        [fig.update_yaxes(title_text=\"Original\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "        [fig.update_xaxes(title_text=\"Predicted\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "        # Customize layout\n",
    "        fig.update_layout(title=\"Original vs. Fitted Data\", template=\"plotly_white\")\n",
    "\n",
    "        # Save as interactive HTML file\n",
    "        fig.write_html(\"original vs predicted.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')\n",
    "# Define the expected column names for the final concatenated DataFrame\n",
    "CULTIVAR = \"Cultivar\" \n",
    "TREATMENT = \"Treatment\"\n",
    "LOCATION = \"Location\"\n",
    "# Create an Excel file with multiple sheets using ExcelWriter\n",
    "output_excel = 'ObsAllData.xlsx'\n",
    "\n",
    "def load_filtered_csv():\n",
    "    with open(\"config_MultiDataFiles.json\", \"r\") as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Load the Excel file\n",
    "\n",
    "    # Initialize an empty list to store filtered DataFrames\n",
    "    filtered_dfs = []\n",
    "    excel_observs = []\n",
    "    global all_treatments, all_locations\n",
    "\n",
    "    # Process each file mentioned in the config\n",
    "    # with pd.ExcelWriter(output_excel) as writer:\n",
    "\n",
    "    for file_name, file_info in config.items():\n",
    "        file_path = os.path.join(FOLDER_PATH, file_name)\n",
    "        if not Path(file_path).exists():\n",
    "            print(f\"Warning: {file_name} not found in {FOLDER_PATH}\")\n",
    "            continue\n",
    "\n",
    "        # Process each sheet\n",
    "        for sheet_info in file_info['sheets']:\n",
    "            # Extract sheet names, cultivars, and treatments\n",
    "            sheet_name = sheet_info['sheet_name']\n",
    "            location = sheet_info['location']\n",
    "            max_observed_buds = sheet_info['max_observed_buds']\n",
    "            cultivar_col, cultivar_name = list(sheet_info['cultivar'].items())[0]\n",
    "            treatment_col, treatment_name = list(sheet_info['treatments'].items())[0]\n",
    "\n",
    "            xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "            raw_df = pd.read_excel(xls, sheet_name = sheet_name)\n",
    "\n",
    "            # Ensure columns exist before filtering\n",
    "            if cultivar_col not in raw_df.columns or treatment_col not in raw_df.columns:\n",
    "                print(f\"Warning: Missing required column(s) in {file_name} - sheet: {sheet_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Rename the Dates to Days of Year (DOY)\n",
    "            doy_column = [pd.to_datetime(col).dayofyear for col in raw_df.columns if utils.is_date_column(col)]\n",
    "            df = raw_df.rename(columns={col:pd.to_datetime(col).dayofyear for col in raw_df.columns if utils.is_date_column(col)})\n",
    "\n",
    "            # Apply filtering for the given cultivar & treatments\n",
    "            filtered_df = df[df[cultivar_col].isin([cultivar_name]) & df[treatment_col].isin([treatment_name])]\n",
    "\n",
    "            # Rename columns\n",
    "            columns_to_select = [cultivar_col] + [treatment_col] + doy_column  # Ensure it's a flat list\n",
    "            filtered_df = filtered_df[columns_to_select]\n",
    "            filtered_df.rename(columns={cultivar_col: CULTIVAR, treatment_col: TREATMENT}, inplace=True)\n",
    "            # Add the LOCATION column to the DataFrame\n",
    "            filtered_df[LOCATION] = location\n",
    "\n",
    "            # Remove rows with any NaN values\n",
    "            filtered_df = filtered_df.dropna()\n",
    "\n",
    "            # Reset index \n",
    "            filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "            # Store the filtered DataFrame\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "            # Generate the output .xlsx file for observations(from experiment data) + predictions(placeholder column: to be valued from APSIM model)\n",
    "\n",
    "            PBB, BB, BudBurstDOY = utils.BB_specifications(filtered_df[doy_column], max_observed_buds)\n",
    "            excel_observ = pd.DataFrame(data={\n",
    "                'SimulationName': f'{sheet_name}{filtered_df[TREATMENT].loc[0].replace(\" \", \"\")}', \n",
    "                                                    'Clock.Today': [col for col in raw_df.columns if utils.is_date_column(col)],\n",
    "                                                    'DOY': doy_column, \n",
    "                                                    LOCATION: filtered_df[LOCATION].loc[0], \n",
    "                                                    TREATMENT: filtered_df[TREATMENT].loc[0],\n",
    "                                                    'KiwiFruit.Phenology.BrokenBuds': BB,\n",
    "                                                    'KiwiFruit.Phenology.ProportionBB': PBB,\n",
    "                                                    'KiwiFruit.Phenology.BudBurstDOY': BudBurstDOY})\n",
    "            \n",
    "            excel_observs.append(excel_observ)\n",
    "\n",
    "    for i, df in enumerate(filtered_dfs):\n",
    "        duplicate_columns = df.columns[df.columns.duplicated()]\n",
    "        if not duplicate_columns.empty:\n",
    "            print(f\"Duplicate columns in DataFrame {i}: {duplicate_columns.tolist()}\")\n",
    "\n",
    "             \n",
    "    final_df = pd.concat(filtered_dfs, ignore_index=True, sort=True).reset_index(drop=True)\n",
    "    excel_observs_df = pd.concat(excel_observs, ignore_index=True, sort=False)\n",
    "\n",
    "\n",
    "    excel_observs_df.to_excel(output_excel, sheet_name='ObsAllData', index=False)\n",
    "\n",
    "\n",
    "    all_treatments = final_df[TREATMENT].unique()\n",
    "    all_locations = final_df[LOCATION].unique()\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def cumulative_and_daily(final_df):\n",
    "\n",
    "    # Calculate cumulative/new daily buds {DayOfYear: [median , std]} for all treatments & all locations\n",
    "    cumulative_daily_treatment = defaultdict(lambda: dict())\n",
    "    new_daily_treatment = defaultdict(lambda: dict())\n",
    "    cumulative_daily_location = defaultdict(lambda: dict())\n",
    "    new_daily_location = defaultdict(lambda: dict())\n",
    "    final_df_treatment_specific = defaultdict(lambda: dict())\n",
    "    final_df_loc_specific = defaultdict(lambda: dict())\n",
    "\n",
    "    for trtmnt in all_treatments:\n",
    "        numeric_columns, nonNumeric_columns = utils.numeric_nonNumeric_col(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "        \n",
    "        final_df_treatment_specific[trtmnt] = utils.interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "        # Calculate median & std for the number of buds per day\n",
    "        numeric_columns_interpol, nonNumeric_columns_interpol = utils.numeric_nonNumeric_col(final_df_treatment_specific[trtmnt])\n",
    "\n",
    "        # For cumulative bud num (median & std), for all locations\n",
    "        cumulative_daily_treatment[trtmnt] = pd.DataFrame({k:v for k,v in zip(['median', 'std'],[[round(final_df_treatment_specific[trtmnt][day].median(),2) for day in numeric_columns_interpol],[np.nan  for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "        # Calculate std only for observed (non-interpolated) values\n",
    "        STD = final_df[final_df[TREATMENT].isin([trtmnt])][numeric_columns].std(ddof=0).dropna()\n",
    "        for idx in STD.index: # insert STD only for indexes of observed data\n",
    "            cumulative_daily_treatment[trtmnt]['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "        # Taking the daily differences between the interpolated days\n",
    "        daily_diff_interpol = utils.find_daily_diff(final_df_treatment_specific[trtmnt]) # all interpolations diff required for median \n",
    "        daily_diff = utils.find_daily_diff(final_df[final_df[TREATMENT].isin([trtmnt])].dropna(axis=1)) # only observation days diff is required for std\n",
    "        # For new daily bud num (median & std), for all locations \n",
    "        new_daily_treatment[trtmnt] = pd.DataFrame({k:v for k,v in zip(['median','std'],[[round(daily_diff_interpol[day].median(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "        STD = daily_diff.std(ddof=0)\n",
    "        for idx in STD.index: # insert STD only for indexes of observed data\n",
    "            new_daily_treatment[trtmnt]['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "    for loc in all_locations:\n",
    "        for trtmnt in all_treatments:\n",
    "            if final_df[final_df[LOCATION].isin([loc]) & final_df[TREATMENT].isin([trtmnt])].empty: # continue if for a given treatment the current location doesn't exist\n",
    "                continue\n",
    "\n",
    "            numeric_columns, nonnumeric_columns = utils.numeric_nonNumeric_col(final_df[final_df[LOCATION].isin([loc]) & final_df[TREATMENT].isin([trtmnt])])\n",
    "            final_df_loc_specific[loc][trtmnt] = utils.interpolate_full_range(final_df[final_df[LOCATION].isin([loc]) & final_df[TREATMENT].isin([trtmnt])])\n",
    "\n",
    "            # For cumulative bud num (median & std), per location\n",
    "            cumulative_daily_location[loc][trtmnt] = pd.DataFrame({k:v for k,v in zip(['median','std'],[[round(final_df_loc_specific[loc][trtmnt][day].median(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "            # Calculate std only for observed (non-interpolated) values\n",
    "            STD = final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])][numeric_columns].std(ddof=0).dropna()\n",
    "            for idx in STD.index: # insert STD only for indexes of observed data\n",
    "                cumulative_daily_location[loc][trtmnt]['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "            # Taking the daily differences between the interpolated days\n",
    "            daily_diff_interpol = utils.find_daily_diff(final_df_loc_specific[loc][trtmnt]) # all interpolations diff required for median \n",
    "            daily_diff = utils.find_daily_diff(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])].dropna(axis=1)) # only observation days diff is required for std\n",
    "            # For new daily bud num (median & std), for all locations \n",
    "            new_daily_location[loc][trtmnt] = pd.DataFrame({k:v for k,v in zip(['median','std'],[[round(daily_diff_interpol[day].median(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "            STD = daily_diff.std(ddof=0)\n",
    "            for idx in STD.index: # insert STD only for indexes of observed data\n",
    "                new_daily_location[loc][trtmnt]['std'][idx] = round(STD[idx],2)\n",
    "    return cumulative_daily_treatment, new_daily_treatment, cumulative_daily_location, new_daily_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = load_filtered_csv()\n",
    "cumulative_daily_treatment, new_daily_treatment, cumulative_daily_location, new_daily_location = cumulative_and_daily(final_df)\n",
    "\n",
    "# Treatment specific plot\n",
    "# treatments_merge =  {'Control (merged)':['Con1', 'Con2', 'Control early', 'Control late', 'Control'], 'HC early (merged)':['HCT1', 'Hi-Cane early', 'HiCane 1'], 'HC late (merged)':['HCT5', 'Hi-Cane late', 'HiCane 5']}\n",
    "# plotter = InteractivePlotGen(cumulative_daily_treatment, new_daily_treatment, treatments_merge)\n",
    "# plotter._BB_treatment_plot(Model_fitting=True, BB_threshold=0.05)\n",
    "\n",
    "# Location specific plot\n",
    "plotter = InteractivePlotGen(cumulative_daily_location, new_daily_location)\n",
    "plotter._BB_location_plot(BB_threshold=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
