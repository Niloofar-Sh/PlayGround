{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_nonNumeric_col(df):\n",
    "    '''\n",
    "    seperates the numeric and non-numeric columns.\n",
    "    '''\n",
    "    return [col for col in df.columns if isinstance(col, int)], [col for col in df.columns if isinstance(col, str)]\n",
    "def interpolate_full_range(df):\n",
    "    # Extract numeric column names\n",
    "    numeric_cols, nonNumeric_cols = numeric_nonNumeric_col(df)\n",
    "\n",
    "    # Function to fill the row with the first valid value\n",
    "    def fill_initial_nans(series):\n",
    "        first_valid_idx = series.first_valid_index()\n",
    "        last_valid_idx = series.last_valid_index()\n",
    "        if first_valid_idx is not None:  # Ensure there's a valid index\n",
    "            series.loc[:first_valid_idx] = series[first_valid_idx]   # Fill initial NaNs\n",
    "        if last_valid_idx is not None:\n",
    "            series.loc[last_valid_idx:] = series[last_valid_idx]\n",
    "        return series\n",
    "\n",
    "    # Apply the function row-wise\n",
    "    df[numeric_cols] = df[numeric_cols].apply(fill_initial_nans, axis=1)\n",
    "\n",
    "    # Create full range of numeric columns from min to max\n",
    "    full_range = np.arange(min(numeric_cols), max(numeric_cols) + 1)\n",
    "\n",
    "    # Reindex DataFrame to include all missing columns\n",
    "    df_numeric = df[numeric_cols].reindex(columns=full_range)\n",
    "\n",
    "    # Interpolate missing values row-wise\n",
    "    df_interpolated = df_numeric.interpolate(method='linear', axis=1)\n",
    "\n",
    "    # Combine back with categorical columns\n",
    "    return pd.concat([df_interpolated, df[nonNumeric_cols]], axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')\n",
    "# Define the expected column names for the final concatenated DataFrame\n",
    "CULTIVAR = \"Cultivar\" \n",
    "TREATMENT = \"Treatment\"\n",
    "LOCATION = \"Location\"\n",
    "\n",
    "# Select the interpolation method\n",
    "interpolation_method = 'linear'#, 'akima', 'pchip', 'quadratic'\n",
    "\n",
    "def is_date_column(col):\n",
    "    # Function to check if column names are dates\n",
    "    try:\n",
    "        pd.to_datetime(col)  # Try converting the column name to a date\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "with open(\"config_MultiDataFiles.json\", \"r\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "# Load the Excel file\n",
    "\n",
    "# Initialize an empty list to store filtered DataFrames\n",
    "filtered_dfs = []\n",
    "\n",
    "# Process each file mentioned in the config\n",
    "for file_name, file_info in config.items():\n",
    "    file_path = os.path.join(FOLDER_PATH, file_name)\n",
    "    # if not file_path.exists():\n",
    "    #     print(f\"Warning: {file_name} not found in {FOLDER_PATH}\")\n",
    "    #     continue\n",
    "\n",
    "    # Process each sheet\n",
    "    for sheet_info in file_info['sheets']:\n",
    "        # Extract sheet names, cultivars, and treatments\n",
    "        sheet_name = sheet_info['sheet_name']\n",
    "        location = sheet_info['location']\n",
    "        cultivar_col, cultivar_name = list(sheet_info['cultivar'].items())[0]\n",
    "        treatment_col, treatment_name = list(sheet_info['treatments'].items())[0]\n",
    "\n",
    "        xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "        df = pd.read_excel(xls, sheet_name = sheet_name)\n",
    "\n",
    "        # Ensure columns exist before filtering\n",
    "        if cultivar_col not in df.columns or treatment_col not in df.columns:\n",
    "            print(f\"Warning: Missing required column(s) in {file_name} - sheet: {sheet_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Rename the Dates to Days of Year (DOY)\n",
    "        doy_column = [pd.to_datetime(col).dayofyear for col in df.columns if is_date_column(col)]\n",
    "        df.rename(columns={col:pd.to_datetime(col).dayofyear for col in df.columns if is_date_column(col)}, inplace=True)\n",
    "\n",
    "        # Apply filtering for the given cultivar & treatments\n",
    "        filtered_df = df[df[cultivar_col].isin([cultivar_name]) & df[treatment_col].isin([treatment_name])]\n",
    "\n",
    "        # Rename columns\n",
    "        columns_to_select = [cultivar_col] + [treatment_col] + doy_column  # Ensure it's a flat list\n",
    "        filtered_df = filtered_df[columns_to_select]\n",
    "        filtered_df.rename(columns={cultivar_col: CULTIVAR, treatment_col: TREATMENT}, inplace=True)\n",
    "        # Add the LOCATION column to the DataFrame\n",
    "        filtered_df[LOCATION] = location\n",
    "\n",
    "        # Remove rows with any NaN values\n",
    "        filtered_df = filtered_df.dropna()\n",
    "\n",
    "        # Reset index \n",
    "        filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "        # Store the filtered DataFrame\n",
    "        filtered_dfs.append(filtered_df)\n",
    "\n",
    "# Concatenate all filtered DataFrames\n",
    "final_df = pd.concat(filtered_dfs, ignore_index=True, sort=True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate cumulative/new daily buds {DayOfYear: [mean , std]} for all treatments & all locations\n",
    "cumulative_daily = defaultdict(lambda: dict())\n",
    "new_daily = defaultdict(lambda: dict())\n",
    "final_df_treatment_loc_specific = defaultdict(lambda: dict())\n",
    "\n",
    "all_treatments = final_df[TREATMENT].unique()\n",
    "all_locations = final_df[LOCATION].unique()\n",
    "\n",
    "for trtmnt in all_treatments:\n",
    "    final_df_treatment_loc_specific[trtmnt]['all_loc'] = interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "    # Calculate mean & std for the number of buds per day\n",
    "    numeric_columns, nonNumeric_cols = numeric_nonNumeric_col(final_df_treatment_loc_specific[trtmnt]['all_loc'])\n",
    "\n",
    "    # For cumulative bud num (mean & std), for all locations\n",
    "    cumulative_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(final_df_treatment_loc_specific[trtmnt]['all_loc'][day].mean(),2) for day in numeric_columns], [round(final_df_treatment_loc_specific[trtmnt]['all_loc'][day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "    \n",
    "    # Taking the daily differences between the interpolated days\n",
    "    diff_daily = final_df_treatment_loc_specific[trtmnt]['all_loc'][numeric_columns].copy()\n",
    "    diff_daily.iloc[:, 1:] = diff_daily.iloc[:, 1:].values - diff_daily.iloc[:, :-1].values\n",
    "    daily_diff = pd.concat([diff_daily,final_df_treatment_loc_specific[trtmnt]['all_loc'][nonNumeric_cols]], axis=1)\n",
    "\n",
    "    # For new daily bud num (mean & std), for all locations \n",
    "    new_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff[day].mean(),2) for day in numeric_columns], [round(daily_diff[day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "    \n",
    "    # For new daily bud num (std), for all locations\n",
    "    # daily_diff_all = final_df_treatment_loc_specific[trtmnt]['all_loc'][[col for col in final_df_treatment_loc_specific[trtmnt]['all_loc'].columns if type(col)==int]].dropna(axis=1).copy()\n",
    "    # daily_diff_all.iloc[:, 1:] = daily_diff_all.diff(axis=1).iloc[:, 1:]  # Compute differences only for columns after the first\n",
    "    # new_daily[trtmnt]['all_loc']['std'] = daily_diff_all.std(ddof=0).values\n",
    "    \n",
    "    for loc in all_locations:\n",
    "        if final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])].empty: # continue if for a given treatment the current location doesn't exist\n",
    "            continue\n",
    "        final_df_treatment_loc_specific[trtmnt][loc] = interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])])\n",
    "\n",
    "        # For cumulative bud num (mean & std), per location\n",
    "        cumulative_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(final_df_treatment_loc_specific[trtmnt][loc][day].mean(),2) for day in numeric_columns], [round(final_df_treatment_loc_specific[trtmnt][loc][day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "        \n",
    "        # Taking the daily differences between the interpolated days\n",
    "        diff_daily = final_df_treatment_loc_specific[trtmnt][loc][numeric_columns].copy()\n",
    "        diff_daily.iloc[:, 1:] = diff_daily.iloc[:, 1:].values - diff_daily.iloc[:, :-1].values\n",
    "        daily_diff = pd.concat([diff_daily,final_df_treatment_loc_specific[trtmnt][loc][nonNumeric_cols]], axis=1)\n",
    "        # For new daily bud num (mean & std), for all locations \n",
    "        new_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff[day].mean(),2) for day in numeric_columns], [round(daily_diff[day].std(ddof=0),2) for day in numeric_columns]])}, index=numeric_columns)\n",
    "    \n",
    "\n",
    "        # For new daily bud num (mean), per location\n",
    "        # new_daily[trtmnt][loc] = cumulative_daily[trtmnt][loc].copy()\n",
    "        # new_daily[trtmnt][loc]['mean'][1:] = new_daily[trtmnt][loc]['mean'].diff()[1:]\n",
    "        # # For new daily bud num (std), per location\n",
    "        # daily_diff_all = final_df_treatment_loc_specific[trtmnt][loc][[col for col in final_df_treatment_loc_specific[trtmnt][loc].columns if type(col)==int]].dropna(axis=1).copy()\n",
    "        # daily_diff_all.iloc[:, 1:] = daily_diff_all.diff(axis=1).iloc[:, 1:]  # Compute differences only for columns after the first\n",
    "        # new_daily[trtmnt][loc]['std'] = daily_diff_all.std(ddof=0).values\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
