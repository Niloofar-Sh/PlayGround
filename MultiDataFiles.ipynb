{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\hranfs\\\\Documents\\\\VS code\\\\PlayGround\\\\utils.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import beta as beta_func  # Beta function\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InteractivePlotGen:\n",
    "    def __init__(self, cumulative, new, treatments_to_merge=False):\n",
    "        self.cumulative = cumulative\n",
    "        self.new = new\n",
    "        self.treatments_to_merge = treatments_to_merge\n",
    "        self.treatments = list(self.cumulative.keys())\n",
    "        self.full_doy_range = self.cumulative[self.treatments[0]]['all_loc'].index\n",
    "    def _BB_treatment_plot(self):\n",
    "        # Create 2 subplots for cumulative and new buds over time\n",
    "        fig = make_subplots(rows=2, cols=1, subplot_titles=[f\"Cumulative Buds\", f\"Daily New Buds\"])\n",
    "\n",
    "        # if ........................\n",
    "        if isinstance(self.treatments_to_merge,dict):\n",
    "            i=1\n",
    "            for merge_key, merge_list in self.treatments_to_merge.items():\n",
    "                merged_treatments_cumulative = pd.concat([self.cumulative[treatment]['all_loc']['mean'] for treatment in merge_list], axis=1).mean(axis=1)\n",
    "                std_concatenated = pd.concat([self.cumulative[treatment]['all_loc']['std'] for treatment in merge_list], axis=1)\n",
    "                pooled_std = np.sqrt((std_concatenated**2).mean(axis=1)) # RMS method\n",
    "                error_minus = np.minimum(pooled_std, merged_treatments_cumulative)  # ensures y - error_minus >= 0\n",
    "                fig.add_trace(go.Scatter(x=self.full_doy_range, y=merged_treatments_cumulative, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True, arrayminus=error_minus),name=f\"{merge_key}\"), row=1, col=1)\n",
    "\n",
    "                # Fit polynomial over all treatments\n",
    "                fitted_cumulative = utils.logistic_fit(np.arange(0,len(self.full_doy_range)), merged_treatments_cumulative)\n",
    "                stats_cumulative = utils.calculate_fit_stats(merged_treatments_cumulative, fitted_cumulative)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=self.full_doy_range, y=fitted_cumulative, mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{merge_key}--fitted'),\n",
    "                row=1, col=1)\n",
    "                fig.add_annotation(\n",
    "                    text=f\"R2 = {stats_cumulative['R2']:.2f}<br>NRMSE = {stats_cumulative['NRMSE']:.2f}\",\n",
    "                    x=self.full_doy_range[int(len(self.full_doy_range)/20)],  # Position at 1/6 of x-axis\n",
    "                    y=(1- 0.2*i)*max(fitted_cumulative+pooled_std),      # Position near the top of y-axis\n",
    "                    showarrow=False,\n",
    "                    xref=\"x1\",  # Referencing x-axis for subplot 1\n",
    "                    yref=\"y1\",  # Referencing y-axis for subplot 1\n",
    "                    font=dict(size=6, color=\"black\"),\n",
    "                    align=\"left\",\n",
    "                    bordercolor=\"black\",\n",
    "                    borderwidth=1,\n",
    "                    bgcolor=\"white\")\n",
    "                # Add an annotation at the BB crossing point\n",
    "                BB_threshold = 0.1*np.max(merged_treatments_cumulative)\n",
    "                idx = np.argmax(merged_treatments_cumulative >= BB_threshold) # Find the first index where y is greater than or equal to 0.1*BB\n",
    "                fig.add_annotation(\n",
    "                    x=list(self.full_doy_range)[idx],\n",
    "                    y=merged_treatments_cumulative.iloc[idx],\n",
    "                    text=f\"BB doy: {list(self.full_doy_range)[idx]}\",\n",
    "                    showarrow=True,\n",
    "                    arrowhead=2,\n",
    "                    ax=50, \n",
    "                    ay=-50)\n",
    "\n",
    "                i+=1\n",
    "        else:\n",
    "             # Add first subplot (Cumulative Sum)\n",
    "            [fig.add_trace(\n",
    "                go.Scatter(x=self.full_doy_range, y=self.cumulative[treatment]['all_loc']['mean'], mode='lines+markers', error_y=dict(type='data', array=self.cumulative[treatment]['all_loc']['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.cumulative[treatment]['all_loc']['std'], self.cumulative[treatment]['all_loc']['mean'])), name=treatment), row=1, col=1) for treatment in self.treatments]\n",
    "\n",
    "\n",
    "        # if  ........................\n",
    "        if isinstance(self.treatments_to_merge,dict):\n",
    "            i=1\n",
    "            for merge_key, merge_list in self.treatments_to_merge.items():\n",
    "                merged_treatments_new = pd.concat([self.new[treatment]['all_loc']['mean'] for treatment in merge_list], axis=1).mean(axis=1)\n",
    "                std_concatenated = pd.concat([self.new[treatment]['all_loc']['std'] for treatment in merge_list], axis=1)\n",
    "                pooled_std = np.sqrt((std_concatenated**2).mean(axis=1)) # RMS method\n",
    "                # Compute the lower error such that it doesn't exceed the mean (to avoid negative values)\n",
    "                error_minus = np.minimum(pooled_std, merged_treatments_new)  # ensures y - error_minus >= 0\n",
    "                fig.add_trace(go.Scatter(x=self.full_doy_range, y=merged_treatments_new, mode='lines+markers', error_y=dict(type='data', array=pooled_std, thickness=1, width=2, visible=True, arrayminus=error_minus),name=f\"{merge_key}\"), row=2, col=1)\n",
    "\n",
    "                # Fit polynomial over all treatments\n",
    "                fitted_new = utils.gaussian_fit(np.arange(0,len(self.full_doy_range)), merged_treatments_new)\n",
    "                stats_new = utils.calculate_fit_stats(merged_treatments_new, fitted_new)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=self.full_doy_range, y=fitted_new, mode='lines', line=dict(color=\"black\", dash=\"dash\") , name=f'{merge_key}--fitted'),\n",
    "                    row=2, col=1)\n",
    "                \n",
    "                fig.add_annotation(\n",
    "                    text=f\"R2 = {stats_new['R2']:.2f}<br>NRMSE = {stats_new['NRMSE']:.2f}\",\n",
    "                    x=self.full_doy_range[int(len(self.full_doy_range)/20)],  # Position at 1/6 of x-axis\n",
    "                    y=(1- 0.2*i)*max(fitted_new+pooled_std),      # Position near the top of y-axis\n",
    "                    showarrow=False,\n",
    "                    xref=\"x2\",  # Referencing x-axis for subplot 2\n",
    "                    yref=\"y2\",  # Referencing y-axis for subplot 2\n",
    "                    font=dict(size=6, color=\"black\"),\n",
    "                    align=\"left\",\n",
    "                    bordercolor=\"black\",\n",
    "                    borderwidth=1,\n",
    "                    bgcolor=\"white\")\n",
    "                i+=1\n",
    "\n",
    "        else:\n",
    "        # Add second subplot (Daily New Buds)\n",
    "            [fig.add_trace(\n",
    "                go.Scatter(x=self.full_doy_range, y=self.new[treatment]['all_loc']['mean'], mode='lines+markers', error_y=dict(type='data', array=self.new[treatment]['all_loc']['std'], thickness=1, width=2, visible=True, arrayminus=np.minimum(self.new[treatment]['all_loc']['std'], self.new[treatment]['all_loc']['mean'])), name=treatment), row=2, col=1) for treatment in self.treatments]\n",
    "\n",
    "\n",
    "        # Set y-axis labels for each subplot\n",
    "        [fig.update_yaxes(title_text=\"Mean bud number\", row=row_num, col=1) for row_num in [1,2]]\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=\"Cumulative & Daily New Buds Over Time\",\n",
    "            showlegend=True,\n",
    "            height=700, width=1200)\n",
    "\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            tickmode=\"array\", \n",
    "            tickvals=self.full_doy_range,  # Use all available dates as ticks\n",
    "            tickangle=45,\n",
    "            tickfont=dict(size=8))  # Rotate for better visibility\n",
    "        \n",
    "\n",
    "        # Save as interactive HTML\n",
    "        fig.write_html(\"bud_num_interactive_plot.html\")\n",
    "    \n",
    "    \n",
    "    # def _BB_location_plot(self):\n",
    "    #     # Create 2 subplots for cumulative and new buds over time\n",
    "    #     fig = make_subplots(rows=2, cols=1, subplot_titles=[f\"Cumulative Buds\", f\"Daily New Buds\"])\n",
    "    #     # Add first subplot (Cumulative Sum)\n",
    "    #     [fig.add_trace(\n",
    "    #         go.Scatter(x=self.full_doy_range, y=self.cumulative[treatment]['all_loc']['mean'], mode='lines+markers', error_y=dict(type='data', array=self.cumulative[treatment]['all_loc']['std'], thickness=1, width=2, visible=True), name=treatment), row=1, col=1) for treatment in self.treatments]\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # def _origin_predict_plot(self):\n",
    "    #     # Create 2 subplots for cumulative and new buds (original vs predicted)\n",
    "    #     fig = make_subplots(rows=2, cols=1, subplot_titles=[\"Cumulative Buds\", \"Daily New Buds\"])\n",
    "\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.fitted_poly['cumulative'], y=self.all_trtmnts['cumulative'].values, mode='markers',\n",
    "    #         name='Original vs Fitted', marker=dict(color='blue')), row=1, col=1)\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.all_trtmnts['cumulative'].values, y=self.all_trtmnts['cumulative'].values, mode='lines',\n",
    "    #         name='Cumulative 1:1', marker=dict(color='red')), row=1, col=1)\n",
    "        \n",
    "    #     # Second subplot\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.fitted_poly['new'], y=self.all_trtmnts['new'].values, mode='markers',\n",
    "    #         name='Original vs Fitted', marker=dict(color='blue')), row=2, col=1)\n",
    "    #     fig.add_trace(go.Scatter(\n",
    "    #         x=self.all_trtmnts['new'].values, y=self.all_trtmnts['new'].values, mode='lines',\n",
    "    #         name='New 1:1', marker=dict(color='red')), row=2, col=1)\n",
    "        \n",
    "        # Add stats as an annotation\n",
    "        # fig.add_annotation(\n",
    "        #     text=f\"R2 = {stats_cumulative['R2']:.2f}<br>NRMSE = {stats_cumulative['NRMSE']:.2f}\",\n",
    "        #     x=fitted_cumulative[int(len(fitted_cumulative)/3)],  # Position at 1/3 of x-axis\n",
    "        #     y=max(fitted_cumulative),      # Position near the top of y-axis\n",
    "        #     showarrow=False,\n",
    "        #     xref=\"x1\",  # Referencing x-axis for subplot 1\n",
    "        #     yref=\"y1\",  # Referencing y-axis for subplot 1\n",
    "        #     font=dict(size=10, color=\"black\"),\n",
    "        #     align=\"left\",\n",
    "        #     bordercolor=\"black\",\n",
    "        #     borderwidth=1,\n",
    "        #     bgcolor=\"white\")\n",
    "        \n",
    "        # fig.add_annotation(\n",
    "        #     text=f\"R2 = {stats_new['R2']:.2f}<br>NRMSE = {stats_new['NRMSE']:.2f}\",\n",
    "        #     x=fitted_new[int(len(fitted_new)/3)],  # Position at 1/3 of x-axis\n",
    "        #     y=max(fitted_new),      # Position near the top of y-axis\n",
    "        #     showarrow=False,\n",
    "        #     xref=\"x2\",  # Referencing x-axis for subplot 2\n",
    "        #     yref=\"y2\",  # Referencing y-axis for subplot 2\n",
    "        #     font=dict(size=10, color=\"black\"),\n",
    "        #     align=\"left\",\n",
    "        #     bordercolor=\"black\",\n",
    "        #     borderwidth=1,\n",
    "        #     bgcolor=\"white\")\n",
    "        \n",
    "    #     # Set x-axis & y-axis labels for each subplot\n",
    "    #     [fig.update_yaxes(title_text=\"Original\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "    #     [fig.update_xaxes(title_text=\"Predicted\", title_font=dict(size=10), row=row_num, col=1) for row_num in [1,2]]\n",
    "    #     # Customize layout\n",
    "    #     fig.update_layout(title=\"Original vs. Fitted Data\", template=\"plotly_white\")\n",
    "\n",
    "    #     # Save as interactive HTML file\n",
    "    #     fig.write_html(\"original vs predicted.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "FOLDER_PATH = os.getenv('FOLDER_PATH')\n",
    "# Define the expected column names for the final concatenated DataFrame\n",
    "CULTIVAR = \"Cultivar\" \n",
    "TREATMENT = \"Treatment\"\n",
    "LOCATION = \"Location\"\n",
    "\n",
    "# Select the interpolation method\n",
    "interpolation_method = 'linear'#, 'akima', 'pchip', 'quadratic'\n",
    "\n",
    "def load_filtered_csv():\n",
    "    with open(\"config_MultiDataFiles.json\", \"r\") as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Load the Excel file\n",
    "\n",
    "    # Initialize an empty list to store filtered DataFrames\n",
    "    filtered_dfs = []\n",
    "    global all_treatments, all_locations\n",
    "\n",
    "    # Process each file mentioned in the config\n",
    "    for file_name, file_info in config.items():\n",
    "        file_path = os.path.join(FOLDER_PATH, file_name)\n",
    "        # if not file_path.exists():\n",
    "        #     print(f\"Warning: {file_name} not found in {FOLDER_PATH}\")\n",
    "        #     continue\n",
    "\n",
    "        # Process each sheet\n",
    "        for sheet_info in file_info['sheets']:\n",
    "            # Extract sheet names, cultivars, and treatments\n",
    "            sheet_name = sheet_info['sheet_name']\n",
    "            location = sheet_info['location']\n",
    "            cultivar_col, cultivar_name = list(sheet_info['cultivar'].items())[0]\n",
    "            treatment_col, treatment_name = list(sheet_info['treatments'].items())[0]\n",
    "\n",
    "            xls = pd.ExcelFile(file_path, engine=\"openpyxl\")\n",
    "            df = pd.read_excel(xls, sheet_name = sheet_name)\n",
    "\n",
    "            # Ensure columns exist before filtering\n",
    "            if cultivar_col not in df.columns or treatment_col not in df.columns:\n",
    "                print(f\"Warning: Missing required column(s) in {file_name} - sheet: {sheet_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Rename the Dates to Days of Year (DOY)\n",
    "            doy_column = [pd.to_datetime(col).dayofyear for col in df.columns if utils.is_date_column(col)]\n",
    "            df.rename(columns={col:pd.to_datetime(col).dayofyear for col in df.columns if utils.is_date_column(col)}, inplace=True)\n",
    "\n",
    "            # Apply filtering for the given cultivar & treatments\n",
    "            filtered_df = df[df[cultivar_col].isin([cultivar_name]) & df[treatment_col].isin([treatment_name])]\n",
    "\n",
    "            # Rename columns\n",
    "            columns_to_select = [cultivar_col] + [treatment_col] + doy_column  # Ensure it's a flat list\n",
    "            filtered_df = filtered_df[columns_to_select]\n",
    "            filtered_df.rename(columns={cultivar_col: CULTIVAR, treatment_col: TREATMENT}, inplace=True)\n",
    "            # Add the LOCATION column to the DataFrame\n",
    "            filtered_df[LOCATION] = location\n",
    "\n",
    "            # Remove rows with any NaN values\n",
    "            filtered_df = filtered_df.dropna()\n",
    "\n",
    "            # Reset index \n",
    "            filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "            # Store the filtered DataFrame\n",
    "            filtered_dfs.append(filtered_df)\n",
    "\n",
    "    # Concatenate all filtered DataFrames\n",
    "    final_df = pd.concat(filtered_dfs, ignore_index=True, sort=True)\n",
    "\n",
    "    all_treatments = final_df[TREATMENT].unique()\n",
    "    all_locations = final_df[LOCATION].unique()\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def cumulative_and_daily(final_df):\n",
    "\n",
    "    # Calculate cumulative/new daily buds {DayOfYear: [mean , std]} for all treatments & all locations\n",
    "    cumulative_daily = defaultdict(lambda: dict())\n",
    "    new_daily = defaultdict(lambda: dict())\n",
    "    final_df_treatment_loc_specific = defaultdict(lambda: dict())\n",
    "\n",
    "    for trtmnt in all_treatments:\n",
    "        numeric_columns, nonNumeric_columns = utils.numeric_nonNumeric_col(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "        \n",
    "        final_df_treatment_loc_specific[trtmnt]['all_loc'] = utils.interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt])])\n",
    "        # Calculate mean & std for the number of buds per day\n",
    "        numeric_columns_interpol, nonNumeric_columns_interpol = utils.numeric_nonNumeric_col(final_df_treatment_loc_specific[trtmnt]['all_loc'])\n",
    "\n",
    "        # For cumulative bud num (mean & std), for all locations\n",
    "        cumulative_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean', 'std'],[[round(final_df_treatment_loc_specific[trtmnt]['all_loc'][day].mean(),2) for day in numeric_columns_interpol],[np.nan  for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "        # Calculate std only for observed (non-interpolated) values\n",
    "        STD = final_df[final_df[TREATMENT].isin([trtmnt])][numeric_columns].std(ddof=0).dropna()\n",
    "        for idx in STD.index: # insert STD only for indexes of observed data\n",
    "            cumulative_daily[trtmnt]['all_loc']['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "        # Taking the daily differences between the interpolated days\n",
    "        daily_diff_interpol = utils.find_daily_diff(final_df_treatment_loc_specific[trtmnt]['all_loc']) # all interpolations diff required for mean \n",
    "        daily_diff = utils.find_daily_diff(final_df[final_df[TREATMENT].isin([trtmnt])].dropna(axis=1)) # only observation days diff is required for std\n",
    "        # For new daily bud num (mean & std), for all locations \n",
    "        new_daily[trtmnt]['all_loc'] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff_interpol[day].mean(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "        STD = daily_diff.std(ddof=0)\n",
    "        for idx in STD.index: # insert STD only for indexes of observed data\n",
    "            new_daily[trtmnt]['all_loc']['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "        for loc in all_locations:\n",
    "            if final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])].empty: # continue if for a given treatment the current location doesn't exist\n",
    "                continue\n",
    "            numeric_columns, nonnumeric_columns = utils.numeric_nonNumeric_col(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])])\n",
    "            final_df_treatment_loc_specific[trtmnt][loc] = utils.interpolate_full_range(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])])\n",
    "\n",
    "            # For cumulative bud num (mean & std), per location\n",
    "            cumulative_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(final_df_treatment_loc_specific[trtmnt][loc][day].mean(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "            # Calculate std only for observed (non-interpolated) values\n",
    "            STD = final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])][numeric_columns].std(ddof=0).dropna()\n",
    "            for idx in STD.index: # insert STD only for indexes of observed data\n",
    "                cumulative_daily[trtmnt][loc]['std'][idx] = round(STD[idx],2)\n",
    "\n",
    "            # Taking the daily differences between the interpolated days\n",
    "            daily_diff_interpol = utils.find_daily_diff(final_df_treatment_loc_specific[trtmnt][loc]) # all interpolations diff required for mean \n",
    "            daily_diff = utils.find_daily_diff(final_df[final_df[TREATMENT].isin([trtmnt]) & final_df[LOCATION].isin([loc])].dropna(axis=1)) # only observation days diff is required for std\n",
    "            # For new daily bud num (mean & std), for all locations \n",
    "            new_daily[trtmnt][loc] = pd.DataFrame({k:v for k,v in zip(['mean','std'],[[round(daily_diff_interpol[day].mean(),2) for day in numeric_columns_interpol], [np.nan for day in numeric_columns_interpol]])}, index=numeric_columns_interpol)\n",
    "    return cumulative_daily, new_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = load_filtered_csv()\n",
    "cumulative_daily, new_daily = cumulative_and_daily(final_df)\n",
    "merge_dict =  {'Control (merged)':['Con1', 'Control early', 'Control'], 'HC early (merged)':['HCT1', 'Hi-Cane early', 'HiCane 1'], 'HC late (merged)':['HCT5', 'Hi-Cane late', 'HiCane 5']}\n",
    "plotter = InteractivePlotGen(cumulative_daily, new_daily, merge_dict)\n",
    "plotter._BB_treatment_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
